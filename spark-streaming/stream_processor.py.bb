from pyspark.sql import SparkSession
from pyspark.sql.functions import from_json, to_json, col
from pyspark.sql.types import StructType, StructField, StringType, MapType

# 1. Spark ì„¸ì…˜ ìƒì„±
spark = SparkSession.builder \
    .appName("KafkaSparkStructuredStreaming") \
    .config("spark.jars.packages", "org.apache.spark:spark-sql-kafka-0-10_2.13:3.3.2,org.apache.spark:spark-token-provider-kafka-0-10_2.13:3.3.2,mysql:mysql-connector-java:8.0.4") \
    .getOrCreate()

spark.sparkContext.setLogLevel("WARN")

# 2. Kafkaì—ì„œ ë°ì´í„° ì½ê¸°
df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "localhost:9092") \
    .option("subscribe", "game-logs") \
    .option("startingOffsets", "latest") \
    .load()

# 3. Kafka ë©”ì‹œì§€ ë””ì½”ë”©
df_decoded = df.selectExpr("CAST(value AS STRING) as json_value")

# 4. JSON íŒŒì‹± ìŠ¤í‚¤ë§ˆ ì •ì˜
schema = StructType([
    StructField("event_type", StringType()),
    StructField("details", MapType(StringType(), StringType()))
])

df_parsed = df_decoded.select(from_json(col("json_value"), schema).alias("data")).select("data.*")



# 5. foreachBatch í•¨ìˆ˜ ì •ì˜
def write_to_mysql(df, batch_id):
    df = df.withColumn("details", to_json(col("details")))  # ğŸ›  detailsë¥¼ JSON ë¬¸ìì—´ë¡œ ë³€í™˜

    df.write \
      .format("jdbc") \
      .option("url", "jdbc:mysql://localhost:3306/gamelogs") \
      .option("driver", "com.mysql.cj.jdbc.Driver") \
      .option("dbtable", "logs") \
      .option("user", "root") \
      .option("password", "root") \
      .mode("append") \
      .save()

# def write_to_mysql(batch_df, batch_id):
#     batch_df.write \
#         .format("jdbc") \
#         .option("url", "jdbc:mysql://localhost:3306/gamelogs") \
#         .option("driver", "com.mysql.cj.jdbc.Driver") \
#         .option("dbtable", "logs") \
#         .option("user", "root") \
#         .option("password", "root") \
#         .mode("append") \
#         .save()
# 6. Streaming ì‹œì‘
query = df_parsed.writeStream \
    .foreachBatch(write_to_mysql) \
    .outputMode("append") \
    .start()

query.awaitTermination()
